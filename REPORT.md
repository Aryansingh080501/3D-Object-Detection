# 3D Object Detection Across KITTI, nuScenes, and Custom PCD Dataset

## 1. Overview

This project implements a complete 3D object detection inference and evaluation pipeline using multiple pretrained models across multiple datasets. The work includes environment setup, inference automation, visualization, metrics comparison, and the introduction of a fully custom PCD dataset requiring new code support. All inference outputs (.png, .ply, .json) and visual results were generated as part of this implementation.

---

## 2. Environment Setup

### Hardware
- NVIDIA GTX 1050 GPU  
- Windows 11  

### Software
- Python 3.10  
- CUDA-enabled PyTorch  
- MMDetection3D, MMCV, MMEngine  
- Open3D, MoviePy, NumPy, Matplotlib  

### Installation Commands
```bash
python -m pip install -U pip
pip install openmim open3d moviepy tqdm matplotlib seaborn pandas
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118
pip install numpy==1.26.4
mim install mmengine
pip install mmcv==2.1.0 mmdet==3.2.0
mim install mmdet3d
```

## 3. Models and Datasets

### Models Evaluated
- **PointPillars (KITTI)**
- **3DSSD (KITTI)**
- **PointPillars (nuScenes)**
- **CenterPoint (nuScenes)**

---

### Datasets

#### **KITTI**
Single-frame LiDAR + image + calibration + label data (frame 000008).

#### **nuScenes**
Single LiDAR sweep with corresponding camera images.

#### **Custom PCD Dataset**
A new dataset introduced and integrated into the pipeline:

data/custom_pcd/
lamppost.pcd
roomscan1.pcd
roomscan2.pcd


To enable this dataset, I implemented:
- `.pcd` loading using Open3D  
- Point cloud normalization (centering, scaling, z-range clamping)  
- Random downsampling for voxelization stability  
- Conversion to KITTI-style `.bin` format  
- Full integration into the unified inference pipeline  

This dataset allows evaluating **model generalization** on non-driving 3D scenes.

## 4. Inference Pipeline

I implemented a unified inference workflow capable of:

- Running multiple pretrained models across multiple datasets  
- Exporting all inference artifacts:
  - `.png` 2D visualizations (KITTI/nuScenes)
  - `.ply` point clouds
  - `.ply` predicted bounding boxes
  - `.json` prediction outputs
- Supporting headless mode for automated batch inference
- Processing multiple `.pcd` files in the custom dataset
- Generating 3D visualization screenshots
- Creating a stitched demo video from inference frames

### Example Inference Command
```bash
python mmdet3d_inference2.py \
  --dataset custom_pcd \
  --input-path data/custom_pcd \
  --model checkpoints/kitti_pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car.py \
  --checkpoint checkpoints/kitti_pointpillars/model.pth \
  --out-dir outputs/custom_pcd_kitti_pointpillars \
  --device cuda:0 \
  --headless
```
The pipeline handles:

- KITTI LiDAR + image
- nuScenes LiDAR
- Custom .pcd → normalized → downsampled → converted → voxelized for inference
- Per-sample visualization and artifact export

## 5. Visualization Outputs

### Open3D 3D Screenshots
To produce consistent and high-quality 3D visualizations, I extended the Open3D viewer script with a new argument:

--camera-view {iso, front, top, side}


This allows capturing standardized viewpoints (e.g., isometric or frontal) for all scenes and models.

Screenshots were generated by running:

```bash
python scripts/open3d_view_saved_ply.py \
  --dir <output_directory> \
  --basename <frame_id> \
  --width 1600 --height 1200 \
  --camera-view iso \
  --save-path results/<output_image>.png \
  --no-show
```
### Demo Video

- A short demonstration video (demo_video.mp4) was generated by stitching together selected inference frames using MoviePy.
The video illustrates 2D projections, 3D bounding boxes, and custom scene behavior across models.



---

## 6. Results and Metrics

### Summary Table

| Model            | Dataset      | Detections | Mean Score | High-Conf (≥0.7) |
|------------------|--------------|------------|------------|------------------|
| PointPillars     | KITTI        | Low        | **0.79**   | Good             |
| 3DSSD            | KITTI        | Many       | 0.25       | Poor             |
| PointPillars     | nuScenes     | Highest    | 0.33       | Few              |
| CenterPoint      | nuScenes     | Moderate   | 0.41       | **Highest**      |
| PointPillars     | Custom PCD   | 0–2        | Very Low   | 0                |
| CenterPoint      | Custom PCD   | Few        | Low        | 0                |

---

### Observations

- **KITTI-trained models** perform best on structured outdoor driving scenes, achieving high-confidence detections.  
- **nuScenes-trained models** are more flexible but often produce lower-confidence predictions.  
- On the **custom PCD dataset**, all models struggle:
  - Indoor and object-scan point clouds have no similarity to autonomous-driving LiDAR distributions.
  - Models often return zero detections or scattered hallucinations.
  - Confidence scores remain extremely low across all custom scenes.

These results clearly highlight the **domain-specific nature** of pretrained 3D detectors and demonstrate the importance of dataset alignment.

## 7. Key Takeaways

1. **PointPillars performs best on KITTI**, producing high-confidence detections and stable bounding boxes on structured outdoor driving scenes.

2. **CenterPoint performs best on nuScenes**, showing better robustness and confidence across diverse object categories and sensor views.

3. The **Custom PCD dataset** highlights major generalization issues:
   - Arbitrary indoor/outdoor point clouds cause most pretrained models to output zero detections.
   - When detections do occur, they are low-confidence or clearly incorrect.
   - This demonstrates how strongly 3D detectors depend on the spatial distribution and sensor characteristics of their training data.

4. **Voxelization-based models assume LiDAR-like distributions.**  
   Custom PCD clouds require normalization, downsampling, and range correction to avoid runtime or CUDA kernel failures.

5. The extended inference pipeline developed here enables:
   - Multi-dataset evaluation,
   - Multi-model comparisons,
   - Visualization automation,
   - And custom dataset support—all of which enhance understanding of 3D model behavior.

## 8. Limitations

- **No ground truth labels** for the custom PCD dataset means that metrics such as mAP or IoU could not be computed for these scenes.
- **Dense indoor point clouds** occasionally produce voxelization issues on GPU despite normalization.  
  These were managed through downsampling and CPU fallback when necessary.
- **Domain mismatch** significantly affects performance:  
  Models pretrained on driving datasets do not generalize to arbitrary 3D point clouds without retraining.
- **Single-frame inference** was used for all datasets; sequence-based temporal models were not evaluated.


## 9. Deliverables

- **REPORT.md**  
  A concise (1–2 page) summary including setup, commands, datasets, models, metrics, screenshots, and insights.

- **results/**  
  - `demo_video.mp4` — a stitched visualization of detections across datasets  
  - ≥4 labeled screenshots from KITTI, nuScenes, and custom PCD datasets  
  - Additional 3D Open3D visualizations

- **Modified Code (clearly commented)**  
  - `mmdet3d_inference2.py`  
    - Added custom PCD dataset support  
    - Point cloud normalization & downsampling  
    - PCD → KITTI .bin conversion  
    - Batch inference support  
  - `open3d_view_saved_ply.py`  
    - Added `--camera-view` option  
    - Implemented front/top/side/isometric presets

- **README.md**  
  Fully reproducible setup instructions, inference commands, visualization scripts, and video generation steps.


